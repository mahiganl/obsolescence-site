---
import BaseLayout from '../../layouts/BaseLayout.astro';
import ChapterNavigation from '../../components/ChapterNavigation.astro';
import ChapterIllustration from '../../components/ChapterIllustration.astro';

const lang = 'en';
const currentSlug = 'chapter-3';

import chapterImage from '../../../assets/colored-drawings/chapter 3.png';
---

<BaseLayout title="Chapter 3 – The Great Relegation" lang={lang} currentSlug={currentSlug}>
  <!-- Part Header -->
  <div class="text-center mb-8">
    <p class="text-4xl sm:text-5xl font-sans font-bold uppercase tracking-wider text-stone-600 dark:text-stone-300">
      PART II
    </p>
    <p class="text-2xl sm:text-3xl font-sans font-bold uppercase tracking-wider text-stone-600 dark:text-stone-300 mt-2">
      THE ECONOMIC RISK
    </p>
  </div>

  <ChapterIllustration src={chapterImage.src} alt="Chapter 3 illustration" lang={lang} />

  <header class="mb-10 text-center">
    <p class="text-sm font-sans uppercase tracking-wider text-stone-500 dark:text-stone-400 mb-2">Chapter 3</p>
    <h1 class="text-4xl sm:text-5xl font-bold text-stone-900 dark:text-stone-100 leading-tight">
      The Great Relegation
    </h1>
  </header>

  <article class="prose mx-auto">
    <p>The first risk is economic disruption.</p>

    <p>The media often caricatures this issue with variations on the theme: "Will AI steal our jobs?" Commentators frequently retort: "It will be just like every other invention. AI will eliminate some jobs and create others. In the meantime, people will suffer, but eventually, we will adapt." Applying this historical logic to the present situation is, in my view, like trying to run obsolete software on an emerging phenomenon we struggle to comprehend.</p>

    <p>That argument might have held water at any other time in history, but this time is different. Most researchers in the field agree that AGI—artificial intelligence capable of performing every task as well as most humans—will arrive within two to ten years. A few outliers speak of 15 or 20 years, but the bulk of forecasts cluster around a five-year horizon.</p>

    <p>Debates abound regarding the true definition of AGI. I find these semantic arguments unproductive. The real question is this: will we have an AI capable of performing a vast array of tasks as well as, if not better than, a human—and doing so faster and cheaper? The answer is almost certainly yes. And the effects will likely be felt well before the end of the decade, perhaps as early as late 2026 or 2027. One of the ingredients currently missing is the ability to execute tasks over long timeframes—to maintain the thread of a project over a day, a week, or a month without drifting.</p>

    <p>However, since 2023, AI time horizons have been doubling every seven to nine months. At this rate, they are projected to reach human levels between 2027 and 2030.</p>

    <p>AGI is not a tool. It is a system capable of performing tasks autonomously, making decisions, and planning sequences of actions to achieve a goal. Thus, the argument that new jobs will be created contains a fatal flaw: why wouldn't AI fill those new jobs as well? Think of it as rapidly rising floodwaters. Those in the valley drown immediately; others seek refuge on higher ground. But as the water keeps rising, it eventually swallows even those who sought shelter at the peaks.</p>

    <p>In "The Intelligence Curse," Luke Drago and Rudolf Laine<a id="ref3" href="#note3"><sup>3</sup></a> explain how agentic AI will induce a "replacement pyramid." This process begins with entry-level positions (data suggests this is already happening in the US), then sweeps away junior employees, middle management, and eventually senior leadership—potentially birthing "all-AI" companies where even the C-Suite is replaced.</p>

    <p>Drago and Laine outline the mechanisms of incentive and competition that will make resistance to this wave of replacement difficult, if not impossible. AI agents will simply be more efficient, faster, and cheaper than human employees.</p>

    <p>Humans will be relegated. They will become economically obsolete. As Emad Mostaque argues in <em>The Last Economy</em><a id="ref4" href="#note4"><sup>4</sup></a>, their value will not just be zero; it will be negative. Retaining human staff will mean incurring extra costs for lower productivity. Beyond wages, there is what Mostaque calls the "metabolic gap": where human labor requires shelter, calories, sleep, and healthcare, AI requires only electricity and computing power. Moreover, since 2023, the price of intelligence has dropped from $37.50 to about $0.14 per million tokens (for GPT-4 equivalent performance)—a 99.7% decline that shows no signs of stopping.</p>

    <hr />

    <p class="text-sm text-stone-500 dark:text-stone-400">
      <a id="note3" href="#ref3"><sup>3</sup></a> Luke Drago and Rudolf Laine, "The Intelligence Curse", April 2025, intelligence-curse.ai.<br />
      <a id="note4" href="#ref4"><sup>4</sup></a> Emad Mostaque, <em>The Last Economy: A Guide to the Age of Intelligent Economics</em>, Intelligent Internet, 2025.
    </p>
  </article>

  <ChapterNavigation lang={lang} currentSlug={currentSlug} />
</BaseLayout>
