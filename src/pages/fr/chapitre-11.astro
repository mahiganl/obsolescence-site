---
import BaseLayout from '../../layouts/BaseLayout.astro';
import ChapterNavigation from '../../components/ChapterNavigation.astro';
import ChapterIllustration from '../../components/ChapterIllustration.astro';

const lang = 'fr';
const currentSlug = 'chapitre-11';

import chapterImage from '../../../assets/colored-drawings/chapter 11.png';
---

<BaseLayout title="Chapitre 11 – Les théories de l'espoir" lang={lang} currentSlug={currentSlug}>
  <ChapterIllustration src={chapterImage.src} alt="Illustration du chapitre 11" lang={lang} />

  <header class="mb-10 text-center">
    <p class="text-sm font-sans uppercase tracking-wider text-stone-500 dark:text-stone-400 mb-2">Chapitre 11</p>
    <h1 class="text-4xl sm:text-5xl font-bold text-stone-900 dark:text-stone-100 leading-tight">
      Les théories de l'espoir
    </h1>
  </header>

  <article class="prose mx-auto">
    <p>Notre résistance passe d'abord par la connaissance. Il faut lire des livres et des articles sur la sûreté de l'IA, écouter des entrevues et des balados, regarder des débats sur le sujet; je fournis à la fin de l'article une courte liste de ressources. Il est difficile de faire le tri dans les discours contradictoires sur le sujet, j'en conviens, mais ces contradictions devraient à tout le moins susciter un début d'inquiétude, car elles montrent qu'il n'y a pas de consensus scientifique.</p>

    <p>Personnellement, j'ai commencé à creuser sérieusement le sujet au début de 2025 sans <em>a priori</em> négatif. Jusque là, j'avais toujours aimé explorer les possibilités créatives qu'ouvrent les nouvelles technologies. Au cours des décennies 2000 et 2010, j'ai participé à l'aventure de l'écriture blog et du livre numérique. Alors que beaucoup, dans le domaine de la littérature, avaient peur du changement, nous étions un certain nombre d'auteurs, rassemblés autour de publie.net notamment, qui explorions les nouvelles formes d'écriture, d'édition et de publication. Ceux qui me connaissent savent que je ne suis pas un technophobe, au contraire. Mais dans le cas des IA avancées, c'est différent. Pour que nous puissions cohabiter harmonieusement avec ces systèmes agentiques, il faudrait un socle de garanties soutenu par un consensus scientifique – toutes choses qui font défaut à l'heure actuelle. Le web et le numérique étaient des outils que nous pouvions nous approprier. Les agents IA sont des entités qui risquent de nous déposséder.</p>

    <p>Je ne dis pas qu'il ne faut pas utiliser les outils qui sont à notre disposition aujourd'hui (sauf exception, nous le faisons tous à des degrés divers de toute façon). Nous ne vivrons plus jamais dans un monde sans IA, et il faut en prendre acte dans tous les domaines. J'ai bien l'intention, en écriture et en littérature, de tirer toutes les conséquences que la révolution induit. Mais comprenons bien que sous la vague réside une puissance océanique qui dépasse de loin les notions connues de médium et de communication.</p>

    <p>Après des mois à baigner dans les discours et les textes sur l'intelligence artificielle, j'ai jugé que les arguments pro-sûreté étaient très solides, alors que les positions non interventionnistes ou accélérationnistes ne tenaient pas la route. Passons en revue quelques arguments de ce qu'on appelle les « théories de l'espoir », qui soutiennent que tout va bien aller.</p>

    <p>En matière économique, j'ai déjà abordé la plupart des arguments : « L'IA ne remplacera pas les humains, elle éliminera certains emplois et en créera d'autres »; « Nous n'atteindrons jamais l'intelligence artificielle générale »; « Les gens vivront grâce à un revenu de base universel (RBU) ». À partir de l'article de Drago et Laine, nous avons mesuré les failles qui traversent ces thèses, en particulier en ce qui a trait aux leviers et aux incitatifs. Bien que la malédiction économique de l'intelligence soit un problème très ardu, il n'est sans doute pas absolument insoluble, puisqu'une partie de la solution réside dans des mécanismes institutionnels que nous connaissons déjà (même si nous avons du mal à les mettre en œuvre et à les rendre inviolables). Quoi qu'il en soit, l'accélération ne peut rien apporter de bon en cette matière, puisqu'elle raccourcit le temps que nous avons pour nous préparer démocratiquement, repenser notre système économique, recréer un équilibre des pouvoirs, etc.</p>

    <p>La plupart des théories de l'espoir portent sur la question du risque existentiel. Commençons par éliminer deux arguments frivoles :</p>

    <ul>
      <li><strong>« Il n'y a qu'à débrancher l'IA. »</strong> Ce n'est pas si simple, il va sans dire : au moment où l'on tentera de la mettre hors service, la SIA aura déjà propagé des copies d'elle-même sur des dizaines ou des milliers de serveurs. Ce serait comme essayer de « débrancher » un virus.</li>
      <li><strong>« L'IA est coincée dans des serveurs, elle n'a pas de corps. Si elle nous tue, elle n'aura plus d'électricité, elle ne pourra pas entretenir les infrastructures, et elle mourra aussi. »</strong> L'IA n'a pas besoin de corps : la manipulation suffit, n'importe quel humain peut devenir ses mains, ses yeux et ses oreilles. Selon des recherches, les IA dont nous disposons actuellement, au début de 2026, sont déjà plus convaincantes que les humains. De toute façon, vu les progrès en robotique, il semble que la superintelligence, lorsqu'elle adviendra, aura des millions de corps artificiels à sa disposition.</li>
    </ul>

    <p>Je précise que la plupart des théoriciens de l'espoir sérieux n'invoquent pas les précédents arguments. Il n'en demeure pas moins que les thèses qu'ils avancent vont dans tous les sens. Parfois, en plein débat (sur la chaîne YouTube Doom Debates par exemple), ils passent d'un argument à l'autre lorsqu'ils se sentent coincés. On dirait que le désir de croire prend le pas sur le raisonnement.</p>

    <p>Voici un petit florilège des arguments qui reviennent souvent :</p>

    <ul>
      <li>« Une entité très intelligente ne serait pas assez stupide pour commettre le génocide d'une espèce » (argument contré par la thèse de l'orthogonalité dont j'ai parlé);</li>
      <li>« Il n'y aura pas une seule superintelligence, mais plusieurs, ce qui créera un équilibre des forces en présence »;</li>
      <li>« Les IA voudront explorer l'univers; pourquoi ne nous laisseraient-elles pas un petit coin de Terre? »;</li>
      <li>« Les IA ne nous élimineront pas car elles voudront nous étudier »;</li>
      <li>« Les IA nous garderont comme animaux de compagnie » (!).</li>
    </ul>

    <p>Je pourrais répondre à chacun de ces arguments. Je ne le ferai pas. Je laisse au lecteur ou à la lectrice le soin de creuser ces questions et de se forger sa propre opinion.</p>

    <p>À l'extrémité du spectre se trouve la thèse du « digne successeur » : l'idée que nous devrions accueillir avec humilité la venue de l'intelligence qui nous remplacera. Cette vue repose sur l'illusion que l'IA sera, d'une certaine manière, une extension de nous-même. En réalité, née d'un entraînement axé sur l'optimisation et la maximisation, dépourvue des mécanismes biologiques de l'empathie et du soin, cette intelligence sera radicalement étrangère (<em>alien</em>). Un système qui possède des valeurs et des visées complètement différentes des nôtres est-il un « digne successeur »?</p>

    <p>Quitte à être qualifié de spéciste, j'ose adopter ici une posture « pro-humain ».</p>
  </article>

  <ChapterNavigation lang={lang} currentSlug={currentSlug} />
</BaseLayout>
