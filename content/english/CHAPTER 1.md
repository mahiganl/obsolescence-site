# BEYOND THE BUBBLE

We don’t talk enough about AI.

Given the deluge of articles, reports, and op-eds that has flooded the media since ChatGPT’s public release in November 2022—a wave that swelled into a tsunami in 2025—the notion that we aren’t talking _enough_ about AI might seem laughable. Yet, considering what we know and what looms on the horizon, we should be discussing it far more—or at the very least, with much greater urgency.

We adapt to progress with startling speed. If we could turn back the clock and tell our 2021 selves what machines would be capable of just five years later, we would be floored. AI’s ability to write better than most humans, speak hundreds of languages, write code from plain English instructions ("vibe coding"), and generate increasingly realistic images and videos from a simple prompt is science fiction made real.

Here is the thing: alongside the rhetoric of tech optimists, accelerationists, transhumanists, posthumanists, and techno-messianists—or simply capitalists sniffing out a profit—there are voices determined to downplay the AI revolution, often repelled by this ideological bloat.

At first glance, this skepticism seems reasonable. Consider "slop"—the mass-produced media sludge churned out by AI and dumped onto social media—or the "hype" inflating the product. Recall AI hallucinations (reminiscent of the disdain for Wikipedia’s inaccuracies in the early 2000s). Look at the theories "proving" AI doesn’t think, or the stupid things AI has said (a flaw, thankfully, that humans are entirely immune to). Or consider the claim that agentic AI—autonomous agents that act in the real world rather than just chatting in a box—is merely a marketing slogan, not a reality.

While prudent, this critical stance misses the genuine disruption represented by recent advances. It is a perspective often found in academia. To avoid being taken in by snake oil salesmen, scholars deconstruct the mechanisms driving the capitalist machine and inflating the bubble. Yet, beneath the surface of the discourse, something extremely powerful is taking shape. We would be wrong to ignore it.

The general public appears to see it differently. If surveys are to be believed, people are far less likely to minimize the threat. According to a 2025 study by the Pew Research Center, about 57% of Americans view the risks of AI for society as "high" or "very high," compared to only 25% who see significant benefits. And 64% fear that AI will reduce the number of jobs available over the next 20 years[^1].

The bubble is real, but that doesn’t mean the technology won’t be transformative. The dot-com bubble burst, but the Internet still reshaped our lives. When a bubble bursts, there is fallout; people suffer. As always, the middle and working classes will foot the bill. But in this context, if it were _just_ a bubble, that would likely be the best-case scenario. If the bursting of the bubble triggered capital flight and slowed progress, that would be even better. However, given the fierce competition between corporations and nations, any slowdown would likely be fleeting.

It is hard to grasp history while it is still being written. We can err by downplaying the impact of technological change just as easily as we can by exaggerating it in the heat of the moment. Still, it is difficult to argue that recent progress in AI is negligible, given how it is already transforming our habits at school, at work, and on the web. The question is not _if_ there is a disruption, but on what scale.

[^1]: Brian Kennedy _et al._, "How Americans View AI and Its Impact on People and Society", Pew Research Center report, September 17, 2025, [https://www.pewresearch.org/science/2025/09/17/how-americans-view-ai-and-its-impact-on-people-and-society/](https://www.pewresearch.org/science/2025/09/17/how-americans-view-ai-and-its-impact-on-people-and-society/) (accessed December 19, 2025).