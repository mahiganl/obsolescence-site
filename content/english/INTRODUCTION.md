_Planned Human Obsolescence_ is intended as an accessible introduction to the problem of AI safety. This essay is written for readers with no prior knowledge of artificial intelligence. No concept is introduced without explanation; no jargon is used without being defined.

This text does not claim to present novel ideas. Rather, it aims to serve a useful purpose by synthesizing the most convincing arguments regarding the risks associated with artificial intelligence as it grows in capability.

Beyond the bubble and the hype, the stated goal of companies like OpenAI, Google, Meta, DeepSeek, or xAI is to create an artificial general intelligence (AGI) capable of performing every task human beings can do—or even an artificial superintelligence (ASI) that would surpass humans in every field.

The implications of such an invention are staggering. Many experts believe that such an AI—equal or superior to humans—could be here by the end of the decade. It threatens to drive wages below subsistence levels, according to Nobel Prize in Economics Joseph Stiglitz, or to escape our control and even wipe us off the map, according to Nobel Prize in Physics Geoffrey Hinton and Turing Prize recipient Yoshua Bengio.

These predictions may seem alarmist, but they are reasonable given the nature of Large Language Models (LLMs). These models are "black boxes." While engineers control the architecture and the learning algorithm, they do not program the models they create. They grow them through a process of autonomous adjustment involving billions of parameters.

AI companies are flying blind, investing staggering sums in raw power and vanishingly little in safety.

We can no longer leave this issue solely to computer scientists. Advanced AI will affect everyone, without exception. It is time for citizens, workers, artists, writers, philosophers, sociologists, politicians, and diplomats to tackle the problem head-on. We do not need to master every mathematical or algorithmic nuance to grasp the essential fact: a powerful, complex, and opaque intelligence is being created, and it carries enormous risks.

Drawing on the work of several thinkers, I address two crucial risks here.

The first is economic: the "Great Relegation"—the obsolescence of the human worker, whose value would become negative compared to much cheaper and more efficient AI agents.

The second is existential: the alignment problem. Will a superintelligence pursue goals compatible with our survival?

If the picture seems bleak, it is because the risks are real. I do not have ready-made answers; we must find paths to solutions together. It is up to us—not a handful of billionaires and the leaders they influence—to decide what shape our societies and our planet will take in the Age of Intelligence.

---

_All drawings accompanying this article were created by Mahigan Lepage and colored using Nano Banana Pro. To view the original grayscale drawings, [click here](https://www.google.com/search?q=%23)._