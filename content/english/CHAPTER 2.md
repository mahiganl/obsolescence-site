# ZOOMING OUT

Some see it as the new iPhone. Others, a shift rivaling the Industrial Revolution. Still others view it as a transformation on the scale of biological history—an evolutionary leap in intelligence itself. As we zoom out, we feel the vertigo. We must, I believe, lean into that vertigo and explore its layers.

Dismissing this new AI as just another gadget is absurd. Is it a disruption comparable to the dawn of the Internet? Even though LLMs are built on web data, their impact promises to be far more profound.

There are many layers to peel back, including the impact on writing—my own field, which I will discuss elsewhere. For now, I will focus on two levels of disruption: economic risk and existential risk. These topics occasionally bubble up in mainstream discourse, but they receive a fraction of the attention they deserve.

We skim over these topics and move on. Why? I believe that between the AI we chat with daily—which looks like Google on steroids and usually seems _nice_ (we mistake sycophancy for politeness)—and the stark, dark portrait painted by certain thinkers regarding probable economic and existential consequences, there is a mental leap most people are not ready to make. We are at a moment in history where playing Cassandra still feels like madness; the Overton window has not yet shifted enough to make it acceptable to suggest that your chatbot risks crushing capitalism or leading humanity to its doom. (Of course, the threat isn't the chatbot itself, but the future iterations of the technology driving it.)

Yet these warnings exist. Nobel economist Joseph Stiglitz argues that AI could, in a worst-case scenario, drive market wages below subsistence levels[^2]. We increasingly hear one of the "Godfathers of AI," Yoshua Bengio—Turing Prize recipient—warning of the dangers of AI matching or surpassing human intelligence. Nobel laureate Geoffrey Hinton echoes this. Conversely, Yann LeCun, another AI heavyweight, mocks these concerns, maintaining that everything will be fine.

This creates confusion: who should we believe when the experts disagree? We must remember that researchers have the same psychological biases as everyone else. Being an AI expert does not make one an AI _thinker_. Most of these researchers, Bengio and Hinton included, worked for decades without dwelling on the consequences of a major breakthrough. At the time, it all seemed so far away.

To truly understand the issue, we cannot rely on computer science alone. We need a bird's-eye view across economics, philosophy, biology, and beyond. I challenge you to find a field of knowledge or a corner of human activity that will be spared. There is none. Since no one possesses deep expertise in every field AI touches, the only viable path is a generalist approach.

That is why I am speaking out—and why I invite philosophers, artists, writers, and autodidacts to join the conversation. It may seem intimidating, but our timidity is delaying a collective realization of AI’s consequences. As we will see, contrary to popular belief, AI researchers know little more than you or I about what is actually happening inside their machines. To address Artificial General Intelligence (AGI), we must, by definition, look at the general picture.

The issue goes far beyond the technical. It is time for us—workers, parents, citizens—to take ownership of the discussion.

[^2]: Anton Korinek and Joseph E. Stiglitz, "Artificial Intelligence and Its Implications for Income Distribution and Unemployment", Working Paper n° 24174, National Bureau of Economic Research, Cambridge, MA, December 2017.