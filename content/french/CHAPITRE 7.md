# UNE NOUVELLE ESPÈCE SUR TERRE

À cette étape, deux questions viennent sans doute à l’esprit des profanes du domaine de la sûreté de l’IA :

1. Pourquoi l’IA voudrait-elle nous éliminer?
2. Comment pourrait-elle y arriver?

Je tenterai de répondre à ces deux questions en dépliant certains notions élaborées par des théoriciens de la sûreté de l’intelligence artificielle.

La question du pourquoi mène souvent la pensée sur une fausse piste : celle de l’IA « méchante », assoiffée de sang. Peu de penseurs envisagent ce genre de psychologie de la machine (bien qu’il soit vrai que l’IA montre déjà des tendances à la tromperie – j’y reviendrai).

Il faut introduire ici une nouvelle notion : celle de « superintelligence », qui, dans le cas de la machine, est souvent appelée « intelligence surhumaine » ou « superintelligence artificielle » – SIA, ou ASI en anglais. Si l’intelligence artificielle générale (IAG) égale la plupart des humains dans la plupart des domaines, la superintelligence artificielle (SIA) surpasse tous les humains dans tous les domaines.

On parle ici d’une IA meilleure que Marie Curie en sciences, meilleure qu’Albert Einstein en physique, meilleure que Marcel Proust en écriture, meilleure qu'Hannah Arendt en philosophie, meilleure que Gueorgui Joukov en stratégie militaire, etc. Cette possibilité repose sur l’hypothèse que l’intelligence humaine n’est pas indépassable; après tout, l’accroissement de la taille de notre cerveau dans l’évolution a été contraint par la nécessité, pour la tête du bébé, de passer à travers le bassin de la mère lors de l’accouchement (ce que les scientifiques appellent le « dilemme obstétrical »). Dans le cas de l’IA, hébergée sur des puces dans des centres de données, le plafond physique ou matériel semble infiniment plus élevé. On peut donc imaginer une SIA non seulement plus futée que tous les humains, mais potentiellement 10 fois, 100 fois, voire 1000 fois ou un million de fois plus intelligente que nous. À cette échelle, il n’y aura pas vraiment de différence entre le quotient intellectuel de John von Neumann et celui de l’idiot du village; les deux seront complètement dépassés.

La plupart des chercheurs en IA croient que nous atteindrons un jour la SIA, même s’ils ne s’entendent pas sur la question du quand. On entend aussi des voix dire que l’IA n’égalera ou ne surpassera jamais cette merveille d’ingénierie qu’est le cerveau humain. Roger Penrose défend l’irréductibilité de la conscience qui, selon lui, reposerait non pas sur des mécanismes algorithmiques, mais bien sur des processus quantiques à l’échelle des microtubules (théorie que beaucoup jugent fumeuse). Il y a dans l’esprit humain, dit Penrose, quelque chose qui échappe au calcul et à la computation. Ce genre d’argument me rappelle ce que disait Freud au sujet des grandes vexations narcissiques de l’humanité (non sans narcissisme, le père de la psychanalyse s’attribuait la paternité de la dernière en date!). L’idée que nous, humains, ne serions plus l’entité la plus intelligente sur la planète est un choc que certains esprits n’arrivent pas à absorber.

Bien sûr, certains diront que l’œuvre de Proust ne se résume pas à la cognition. « Chaque jour j’attache moins de prix à l’intelligence », écrivait-il dans l’incipit de *Contre Sainte-Beuve*. Personne ne dit que la superintelligence traversera l’expérience existentielle et sensorielle sous-tendant l’écriture de la *Recherche du temps perdu*, ni même qu’elle *voudra* écrire une telle œuvre sortie d’une mémoire intuitive proprement humaine. Ce que je dis, c’est que si elle le désirait ou si on avait le pouvoir de lui ordonner de le faire, la superintelligence *pourrait* écrire un livre plus génial encore que l’œuvre de Proust, y compris en pinçant toutes les cordes de l’intuition et du sentiment qui font vibrer les lecteurs – même s’il est probable que pendant les secondes ou les minutes où l’IA produirait son chef-d’œuvre, elle resterait parfaitement de glace. Je crois de toute façon qu’avant d’arriver à la SIA, en route vers l’intelligence générale, on verra apparaître des œuvres qui, sans forcément dépasser les sommets atteints par Proust ou Virginia Woolf, nous émerveilleront par leur force créative, presque à notre corps défendant.

On peut bien dire que l’art déborde l’intelligence, ce qui est vrai. Reste que si une intelligence supérieure a un but, y compris un objectif de rendu émotionnel – par exemple, faire pleurer celui ou celle qui écoute une chanson, ou rédiger un scénario de film qui touche à ce qu’il y a de plus humain en nous –, elle optimisera tous les moyens techniques dont elle dispose pour y arriver, et nous n’y verrons que du feu. On peut aussi se repasser le foulard autour du cou et tenter de brouiller la conversation en disant : « D’accord, mais au fond, c’est quoi l’intelligence, tu vois? » Je ne crois pas qu’il soit utile d’entrer dans des débats sémantiques. Inspirée de différents penseurs de l’IA, la définition que je retiens est la suivante : la capacité à former une cartographie précise du réel et à tirer l’avenir dans la direction que l’on choisit. C’est ce que les humains font sur Terre – imparfaitement – depuis qu’ils y occupent le plus haut échelon de l’intelligence et de la chaîne alimentaire. Ils élaborent une représentation non pas exacte, mais précise du réel (un « modèle de monde »), et ils tirent l’avenir dans la direction qu’ils ont « choisie » en tant que collectif (même si, pour certains membres du collectif, cette direction paraît parfois mal avisée). Nous avons si bien réussi à façonner la planète (à la « tirer » dans notre direction) que l’on parle maintenant d’Anthropocène pour décrire l’ère géologique actuelle de la Terre. 

La SIA sera une nouvelle espèce sur la planète. Le mot « espèce » peut choquer, puisqu’il est normalement réservé aux êtres biologiques. Or, la notion permet de comprendre ce qui se joue dans les centres de données des sociétés d’IA. Plusieurs croient que les IA avec lesquelles nous interagissons au quotidien sont des logiciels créés par des programmeurs. Ce n’est pas le cas. On programme l’*instrument* pour créer l’IA (l’architecture et l’algorithme d’apprentissage), pas l’IA elle-même. Plusieurs essayistes anglophones utilisent les expressions *to grow* ou *to breed* pour parler du processus de création des IA : on les cultive comme des végétaux, on les élève comme des animaux. C’est pourquoi ces intelligences sont si imprévisibles et si difficiles à contrôler. Ce sont des boîtes noires qu’on arrive mal à sonder. Le domaine de la recherche en IA qui consiste à tenter de comprendre ce qui se passe dans ces boîtes s’appelle « l’interprétabilité ». C’est un champ d’étude embryonnaire qui, jusqu’à maintenant, a rapporté bien peu de connaissances scientifiques – tout juste quelques faisceaux dans la nuit. Les produits commercialisés comme ChatGPT incluent des couches de protection par-dessus le LLM, mais ces garde-fous font souvent défaut, comme le montrent certains cas médiatisés en 2024 et 2025 : ChatGPT qui aide un jeune à se suicider, ou les personnes poussées vers la psychose par leur robot conversationnel. Si les IA étaient des logiciels, il suffirait de passer une variable à « faux », comme « allow_teen_suicide = False » ou « induce_human_psychosis = False », mais ces commandes n’existent évidemment pas.